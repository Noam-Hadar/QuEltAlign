{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348b9580-9226-46f1-b881-bde8420cd8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages if not already installed\n",
    "# pip3 install pandas primer3-py pyfaidx biopython networkx matplotlib numpy scipy\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from glob import glob\n",
    "from time import sleep\n",
    "from itertools import product\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# External library imports\n",
    "import pandas as pd\n",
    "import primer3\n",
    "from pyfaidx import Fasta\n",
    "from Bio.Blast import NCBIWWW, NCBIXML\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define constants\n",
    "fastq = 'output_reads.fastq'  # Input FASTQ file name\n",
    "quality = 0.1  # Minimal quality Phred score\n",
    "min_size = 20  # Minimum sequence length after trimming\n",
    "min_overlap = 50  # Minimal overlap for de novo assembly\n",
    "runs = 10\n",
    "\n",
    "# Phred quality score mapping\n",
    "phredict = {\n",
    "    c: 10 ** (-(ord(c) - 33) / 10.0) for c in \n",
    "    \"!\\\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJK\"\n",
    "}\n",
    "\n",
    "# Function to extract high-quality sequences\n",
    "def extract_high_quality_sequences(fastq_file, quality_threshold, min_size):\n",
    "    sequences = []\n",
    "    with open(fastq_file, 'r', encoding='utf-8-sig') as f:\n",
    "        lines = f.readlines()\n",
    "        for i in range(0, len(lines), 4):\n",
    "            current_sequence = lines[i + 1].strip()\n",
    "            quality_scores = lines[i + 3].strip()\n",
    "            #phred_scores = [phredict[char] for char in quality_scores]\n",
    "            phred_scores = [phredict['F'] for char in quality_scores]\n",
    "\n",
    "            # Filter low-quality bases\n",
    "            high_quality_sequence = ''.join(\n",
    "                [\n",
    "                    current_sequence[j]\n",
    "                    for j in range(len(current_sequence))\n",
    "                    if phred_scores[j] <= quality_threshold\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # Check minimum size constraint\n",
    "            if len(high_quality_sequence) >= min_size:\n",
    "                sequences.append(high_quality_sequence)\n",
    "\n",
    "    return sequences\n",
    "\n",
    "# Extract sequences and remove duplicates\n",
    "high_quality_sequences = extract_high_quality_sequences(fastq, quality, min_size)\n",
    "unique_sequences = sorted(set(high_quality_sequences))\n",
    "\n",
    "# Save unique sequences to file\n",
    "with open('sequences.txt', 'w') as output_file:\n",
    "    output_file.write('\\n'.join(unique_sequences))\n",
    "\n",
    "# Calculate nucleotide composition\n",
    "def calculate_nucleotide_composition(sequences):\n",
    "    total_len = sum(len(seq) for seq in sequences)\n",
    "    composition = {\n",
    "        'A': round(sum(seq.count('A') for seq in sequences) / total_len * 100, 2),\n",
    "        'T': round(sum(seq.count('T') for seq in sequences) / total_len * 100, 2),\n",
    "        'C': round(sum(seq.count('C') for seq in sequences) / total_len * 100, 2),\n",
    "        'G': round(sum(seq.count('G') for seq in sequences) / total_len * 100, 2),\n",
    "    }\n",
    "    return composition\n",
    "\n",
    "nucleotide_composition = calculate_nucleotide_composition(unique_sequences)\n",
    "\n",
    "# Print nucleotide composition\n",
    "print(\"Nucleotide Composition:\")\n",
    "for nucleotide, percentage in nucleotide_composition.items():\n",
    "    print(f\"{nucleotide}: {percentage}%\")\n",
    "\n",
    "def getReverseComplement(sequence):\n",
    "    return sequence.upper().replace('T','a').replace('A', 't').replace('G', 'c').replace('C', 'g').upper()[::-1]\n",
    "\n",
    "def overlap_length(s1, s2):\n",
    "    max_len = min(len(s1), len(s2))\n",
    "    for n in range(max_len, 0, -1):\n",
    "        if s1.endswith(s2[:n]):\n",
    "            return n\n",
    "    return 0\n",
    "\n",
    "def maxOverlap(s1, s2):\n",
    "    right = overlap_length(s1, s2)\n",
    "    left = overlap_length(s2, s1)\n",
    "    return max([right, left])\n",
    "\n",
    "sequences = [seq.strip() for seq in open(\"sequences.txt\").readlines() if len(seq.strip()) > min_overlap]\n",
    "for sequence in sequences:\n",
    "    reverseComplement = getReverseComplement(sequence)\n",
    "    if reverseComplement in sequences:\n",
    "        sequences.remove(sequence)\n",
    "sequences = sorted(sequences)\n",
    "\n",
    "# Function to generate an Overlap Graph\n",
    "def overlap_graph(sequences, min_overlap):\n",
    "    \"\"\"Constructs an overlap graph from the given sequences.\"\"\"\n",
    "    edges = []\n",
    "    for s1 in sequences:\n",
    "        for s2 in sequences:\n",
    "            if s1 != s2:\n",
    "                overlap = overlap_length(s1, s2)\n",
    "                if overlap >= min_overlap:\n",
    "                    edges.append((s1, s2, overlap))\n",
    "    return edges\n",
    "\n",
    "# Generate Overlap Graph\n",
    "sequences = [seq.strip() for seq in open(\"sequences.txt\").readlines() if len(seq.strip()) > min_overlap]\n",
    "\n",
    "# Create overlap graph edges\n",
    "overlap_edges = overlap_graph(sequences, min_overlap)\n",
    "\n",
    "# Build a directed graph using NetworkX\n",
    "G = nx.DiGraph()\n",
    "for s1, s2, overlap in overlap_edges:\n",
    "    G.add_edge(s1, s2, weight=overlap)\n",
    "\n",
    "# Draw the overlap graph\n",
    "def draw_overlap_graph(G, output_filename = 'Results/overlap_graph.svg'):\n",
    "    #Draws the overlap graph and saves it to a file.\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    edge_labels = {\n",
    "        (u, v): f\"{G[u][v]['weight']}\"\n",
    "        for u, v in G.edges\n",
    "    }\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    nx.draw(\n",
    "        G,\n",
    "        pos,\n",
    "        with_labels=True,\n",
    "        node_size=1,\n",
    "        node_color='lightblue',\n",
    "        font_size=1,\n",
    "        font_weight='bold',\n",
    "        arrowsize=1,\n",
    "    )\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
    "    plt.title('Overlap Graph')\n",
    "    plt.savefig(output_filename)\n",
    "    plt.clf()\n",
    "\n",
    "# Function to assemble genome with \"-\" in overlaps\n",
    "def assemble_genome_with_gaps(G):\n",
    "    \"\"\"Assembles the genome with overlaps represented by a '-' character.\"\"\"\n",
    "    assembled_genomes = []\n",
    "    utilization_scores = []\n",
    "\n",
    "    # Iterate through connected components of the graph\n",
    "    for component in nx.weakly_connected_components(G):\n",
    "        subgraph = G.subgraph(component)\n",
    "        genome = \"\"\n",
    "\n",
    "        # Find a starting node\n",
    "        start_node = None\n",
    "        for node in subgraph.nodes:\n",
    "            if subgraph.in_degree(node) == 0:\n",
    "                start_node = node\n",
    "                break\n",
    "        if start_node is None:\n",
    "            # Handle cyclic cases\n",
    "            start_node = next(iter(subgraph.nodes))\n",
    "\n",
    "        # Traverse the path to build the genome\n",
    "        current_sequence = start_node\n",
    "        genome = current_sequence\n",
    "        visited = set([current_sequence])\n",
    "\n",
    "        while True:\n",
    "            # Find the next node with the highest overlap\n",
    "            successors = list(subgraph.successors(current_sequence))\n",
    "            if not successors:\n",
    "                break\n",
    "\n",
    "            next_sequence = max(\n",
    "                successors, key=lambda x: G[current_sequence][x][\"weight\"]\n",
    "            )\n",
    "            overlap = G[current_sequence][next_sequence][\"weight\"]\n",
    "\n",
    "            genome += \"-\" + next_sequence[overlap:]\n",
    "            visited.add(next_sequence)\n",
    "            current_sequence = next_sequence\n",
    "\n",
    "        assembled_genomes.append(genome)\n",
    "        utilization_scores.append(len(visited) / len(component) * 100)\n",
    "\n",
    "    return assembled_genomes, utilization_scores\n",
    "\n",
    "def assemble_genome_from_overlap_graph(G):\n",
    "    \"\"\"Assembles the genome by traversing the overlap graph.\"\"\"\n",
    "    assembled_genomes = []\n",
    "\n",
    "    # Iterate through connected components of the graph\n",
    "    for component in nx.weakly_connected_components(G):\n",
    "        subgraph = G.subgraph(component)\n",
    "        genome = \"\"\n",
    "\n",
    "        # Find a starting node\n",
    "        start_node = None\n",
    "        for node in subgraph.nodes:\n",
    "            if subgraph.in_degree(node) == 0:\n",
    "                start_node = node\n",
    "                break\n",
    "        if start_node is None:\n",
    "            # Handle cyclic cases\n",
    "            start_node = next(iter(subgraph.nodes))\n",
    "\n",
    "        # Traverse the path to build the genome\n",
    "        current_sequence = start_node\n",
    "        genome = current_sequence\n",
    "        visited = set([current_sequence])\n",
    "\n",
    "        while True:\n",
    "            # Find the next node with the highest overlap\n",
    "            successors = list(subgraph.successors(current_sequence))\n",
    "            if not successors:\n",
    "                break\n",
    "\n",
    "            next_sequence = max(\n",
    "                successors, key=lambda x: G[current_sequence][x][\"weight\"]\n",
    "            )\n",
    "            overlap = G[current_sequence][next_sequence][\"weight\"]\n",
    "\n",
    "            genome += next_sequence[overlap:]\n",
    "            visited.add(next_sequence)\n",
    "            current_sequence = next_sequence\n",
    "\n",
    "        assembled_genomes.append(genome)\n",
    "\n",
    "    return assembled_genomes\n",
    "\n",
    "\n",
    "# Assemble genomes\n",
    "assembled_genomes = assemble_genome_from_overlap_graph(G)\n",
    "assembled_genomes_with_gaps, utilization_scores = assemble_genome_with_gaps(G)\n",
    "\n",
    "# Save assembled genomes and utilization scores to files\n",
    "with open('overlap_assembled_genomes.txt', 'w') as output_file:\n",
    "    output_file.write(\"\\n\".join(assembled_genomes))\n",
    "\n",
    "with open('overlap_assembled_genomes_with_gaps.txt', 'w') as output_file:\n",
    "    output_file.write(\"\\n\".join(assembled_genomes_with_gaps))\n",
    "\n",
    "with open('utilization_scores.txt', 'w') as output_file:\n",
    "    output_file.write(\"\\n\".join(f\"{score:.2f}%\" for score in utilization_scores))\n",
    "\n",
    "# Draw and save the overlap graph\n",
    "draw_overlap_graph(G)\n",
    "\n",
    "df = pd.DataFrame([assembled_genomes, assembled_genomes_with_gaps, utilization_scores]).T\n",
    "df.columns = ['Assembled Genome', 'Assembled Genome with Junctions', 'Raw Sequences Utilization']\n",
    "df = df.sort_values('Raw Sequences Utilization', ascending = False, ignore_index = True)\n",
    "\n",
    "# Read the result file\n",
    "df = df.head()\n",
    "\n",
    "def getAlignmentSummary(hsp):\n",
    "    # Parse XML\n",
    "    root = ET.fromstring(hsp)\n",
    "    \n",
    "    # Extract values\n",
    "    fields = {\n",
    "        \"Hsp_num\": root.find(\"Hsp_num\").text,\n",
    "        \"Bit Score\": root.find(\"Hsp_bit-score\").text,\n",
    "        \"Score\": root.find(\"Hsp_score\").text,\n",
    "        \"E-value\": root.find(\"Hsp_evalue\").text,\n",
    "        \"Query Start\": root.find(\"Hsp_query-from\").text,\n",
    "        \"Query End\": root.find(\"Hsp_query-to\").text,\n",
    "        \"Hit Start\": root.find(\"Hsp_hit-from\").text,\n",
    "        \"Hit End\": root.find(\"Hsp_hit-to\").text,\n",
    "        \"Query Frame\": root.find(\"Hsp_query-frame\").text,\n",
    "        \"Hit Frame\": root.find(\"Hsp_hit-frame\").text,\n",
    "        \"Identity\": root.find(\"Hsp_identity\").text,\n",
    "        \"Positive Matches\": root.find(\"Hsp_positive\").text,\n",
    "        \"Gaps\": root.find(\"Hsp_gaps\").text,\n",
    "        \"Alignment Length\": root.find(\"Hsp_align-len\").text,\n",
    "        \"Query Sequence\": root.find(\"Hsp_qseq\").text,\n",
    "        \"Hit Sequence\": root.find(\"Hsp_hseq\").text,\n",
    "        \"Midline\": root.find(\"Hsp_midline\").text,\n",
    "    }\n",
    "    # Generate HTML\n",
    "    alignment_summary = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "        <title>BLASTn Result</title>\n",
    "        <style>\n",
    "            body {{ font-family: Arial, sans-serif; line-height: 1.6; margin: 20px; }}\n",
    "            .table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}\n",
    "            .table th, .table td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n",
    "            .table th {{ background-color: #f4f4f4; }}\n",
    "            .sequences {{ white-space: pre-wrap; font-family: monospace; background: #f9f9f9; padding: 10px; }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>BLASTn Result</h1>\n",
    "        <table class=\"table\">\n",
    "            <tr><th>Field</th><th>Value</th></tr>\n",
    "            {''.join(f\"<tr><td>{key}</td><td>{value}</td></tr>\" for key, value in fields.items() if key not in ['Query Sequence', 'Hit Sequence', 'Midline'])}\n",
    "        </table>\n",
    "        <h2>Alignment</h2>\n",
    "        <div class=\"sequences\">\n",
    "            <strong>Query Sequence:</strong><br>{fields['Query Sequence']}<br><br>\n",
    "            <strong>Midline:</strong><br>{fields['Midline']}<br><br>\n",
    "            <strong>Hit Sequence:</strong><br>{fields['Hit Sequence']}\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    alignment_summary = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "        <title>BLASTn Result</title>\n",
    "        <style>\n",
    "            body {{ font-family: Arial, sans-serif; line-height: 1.6; margin: 20px; }}\n",
    "            .table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}\n",
    "            .table th, .table td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n",
    "            .table th {{ background-color: #f4f4f4; }}\n",
    "            .sequences {{ white-space: pre-wrap; font-family: monospace; background: #f9f9f9; padding: 10px; }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>BLASTn Result</h1>\n",
    "        <table class=\"table\">\n",
    "            <tr><th>Field</th><th>Value</th></tr>\n",
    "            {''.join(f\"<tr><td>{key}</td><td>{value}</td></tr>\" for key, value in fields.items() if key not in ['Query Sequence', 'Hit Sequence', 'Midline'])}\n",
    "        </table>\n",
    "        <h2>Alignment</h2>\n",
    "        <div class=\"sequences\">\n",
    "            {fields['Query Sequence']}\n",
    "            {fields['Midline']}\n",
    "            {fields['Hit Sequence']}\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    return alignment_summary\n",
    "\n",
    "\n",
    "# BLASTn search function\n",
    "def blastn_search(seq, query_index):\n",
    "    print(f\"Processing sequence {query_index + 1}...\")\n",
    "    try:\n",
    "        # Submit BLAST query\n",
    "        result_handle = NCBIWWW.qblast('blastn', 'nt', seq)\n",
    "        sleep(10)  # Delay to avoid overloading the server\n",
    "\n",
    "        # Save result to a temporary file\n",
    "        result = result_handle.read()\n",
    "        query_id = f\"Query_{query_index + 1}\"\n",
    "        output_file = f\"{query_id}_blast_output.xml\"\n",
    "        with open(output_file, 'w') as f:\n",
    "            f.write(result)\n",
    "\n",
    "        # Parse BLAST output\n",
    "        xml = open(output_file, 'r').read()\n",
    "        hsp = '<Hsp>' + xml.split('<Hsp>')[1].split('</Hsp>')[0] + '</Hsp>'\n",
    "        return getAlignmentSummary(hsp)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing sequence {query_index + 1}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Apply BLASTn search to all sequences\n",
    "df['BLASTn'] = df['Assembled Genome'].apply(lambda seq: blastn_search(seq, df.index[df['Assembled Genome'] == seq][0]))\n",
    "\n",
    "# Clean up temporary files\n",
    "for output_file in glob('*_blast_output.xml'):\n",
    "    os.remove(output_file)\n",
    "\n",
    "print(\"BLASTn processing completed\")\n",
    "\n",
    "# Function to calculate primers using Primer3\n",
    "def calculate_primers(sequence):\n",
    "    try:\n",
    "        primers = primer3.design_primers(\n",
    "            {\n",
    "                'SEQUENCE_ID': 'an_id',\n",
    "                'SEQUENCE_TEMPLATE': sequence,\n",
    "                'SEQUENCE_TARGET': [350, 100]\n",
    "            },\n",
    "            {\n",
    "                'PRIMER_TASK': 'generic',\n",
    "                'PRIMER_PICK_LEFT_PRIMER': 1,\n",
    "                'PRIMER_PICK_INTERNAL_OLIGO': 0,\n",
    "                'PRIMER_PICK_RIGHT_PRIMER': 1,\n",
    "                'PRIMER_NUM_RETURN': 10,\n",
    "                'PRIMER_OPT_SIZE': 20,\n",
    "                'PRIMER_MIN_SIZE': 18,\n",
    "                'PRIMER_MAX_SIZE': 27,\n",
    "                'PRIMER_OPT_TM': 58.0,\n",
    "                'PRIMER_MIN_TM': 57.0,\n",
    "                'PRIMER_MAX_TM': 63.0,\n",
    "                'PRIMER_MIN_GC': 20.0,\n",
    "                'PRIMER_MAX_GC': 80.0,\n",
    "                'PRIMER_MAX_POLY_X': 5,\n",
    "                'PRIMER_SALT_MONOVALENT': 50.0,\n",
    "                'PRIMER_DNA_CONC': 50.0,\n",
    "                'PRIMER_MAX_NS_ACCEPTED': 0,\n",
    "                'PRIMER_MAX_SELF_ANY': 12,\n",
    "                'PRIMER_MAX_SELF_END': 8,\n",
    "                'PRIMER_PAIR_MAX_COMPL_ANY': 12,\n",
    "                'PRIMER_PAIR_MAX_COMPL_END': 8,\n",
    "                'PRIMER_PRODUCT_SIZE_RANGE': [[100, 800]]\n",
    "            }\n",
    "        )\n",
    "        return primers\n",
    "    except Exception as e:\n",
    "        print(f\"Primer design failed for sequence. Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to generate primers for a genome\n",
    "def generate_primers(genome):\n",
    "    header = [\n",
    "        'Primer left', 'Primer right', \n",
    "        'Primer left Tm (째C)', 'Primer right Tm (째C)', \n",
    "        'Product size (bp)', 'Product sequence'\n",
    "    ]\n",
    "    lines = []\n",
    "    window_size = 800\n",
    "    step_size = 400\n",
    "\n",
    "    for i in range(0, len(genome) - window_size, step_size):\n",
    "        sequence = genome[i:i + window_size]\n",
    "        primers = calculate_primers(sequence)\n",
    "\n",
    "        if primers and 'PRIMER_LEFT_1_SEQUENCE' in primers and 'PRIMER_RIGHT_1_SEQUENCE' in primers:\n",
    "            try:\n",
    "                # Extract primer information\n",
    "                primer_left = primers['PRIMER_LEFT_1_SEQUENCE']\n",
    "                primer_right = primers['PRIMER_RIGHT_1_SEQUENCE']\n",
    "                primer_left_Tm = round(primers['PRIMER_LEFT_1_TM'], 2)\n",
    "                primer_right_Tm = round(primers['PRIMER_RIGHT_1_TM'], 2)\n",
    "                product_size = primers['PRIMER_PAIR_1_PRODUCT_SIZE']\n",
    "\n",
    "                # Generate reverse complement of right primer\n",
    "                primer_right_flipped = primer_right[::-1].translate(\n",
    "                    str.maketrans(\"ACGT\", \"TGCA\")\n",
    "                )\n",
    "\n",
    "                # Extract product sequence\n",
    "                product_sequence = (\n",
    "                    sequence.split(primer_left)[1].split(primer_right_flipped)[0]\n",
    "                )\n",
    "                product_sequence = primer_left + product_sequence + primer_right_flipped\n",
    "\n",
    "                # Store results\n",
    "                line = [\n",
    "                    primer_left, primer_right, \n",
    "                    primer_left_Tm, primer_right_Tm, \n",
    "                    product_size, product_sequence\n",
    "                ]\n",
    "                lines.append(line)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing primers: {e}\")\n",
    "                continue\n",
    "\n",
    "    return lines\n",
    "\n",
    "# Apply primer generation to dataframe\n",
    "df['PCR_validation_settings'] = df['Assembled Genome'].apply(generate_primers)\n",
    "\n",
    "# Save the results as a pickle file\n",
    "df.to_pickle('results.pkl')\n",
    "print(\"Primer design completed. Results saved to 'results.pkl'.\")\n",
    "\n",
    "# Constants for nucleotide percentages\n",
    "minSize = 100  # Adjust as needed\n",
    "As, Ts, Cs, Gs = 25.0, 25.0, 25.0, 25.0  # Example raw percentages\n",
    "\n",
    "# Function to calculate nucleotide percentages\n",
    "def nuc_percentage(genome, As, Ts, Cs, Gs, output_filename):\n",
    "    gAs = round(genome.count('A') / len(genome) * 100, 2)\n",
    "    gTs = round(genome.count('T') / len(genome) * 100, 2)\n",
    "    gCs = round(genome.count('C') / len(genome) * 100, 2)\n",
    "    gGs = round(genome.count('G') / len(genome) * 100, 2)\n",
    "    labels = ['A', 'T', 'C', 'G']\n",
    "    sequence_1 = [As, Ts, Cs, Gs]\n",
    "    sequence_2 = [gAs, gTs, gCs, gGs]\n",
    "\n",
    "    bar_width = 0.35\n",
    "    r1 = np.arange(len(sequence_1))\n",
    "    r2 = [x + bar_width for x in r1]\n",
    "\n",
    "    plt.bar(r1, sequence_1, width=bar_width, label='Raw Data', alpha=0.7)\n",
    "    plt.bar(r2, sequence_2, width=bar_width, label='Assembly', alpha=0.7)\n",
    "\n",
    "    plt.xticks([r + bar_width / 2 for r in range(len(sequence_1))], labels, fontsize = 40)\n",
    "    plt.yticks(fontsize = 40)\n",
    "    plt.ylabel('Percentage', fontsize = 40)\n",
    "    plt.title('Nucleotide Composition', fontsize = 40)\n",
    "    plt.legend(fontsize=35, markerscale=5)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_filename, format='svg')\n",
    "    plt.clf()\n",
    "\n",
    "# Function to generate De Bruijn graph\n",
    "def de_bruijn(sequence, k, output_filename):\n",
    "    edges = [(sequence[i:i + k - 1], sequence[i + 1:i + k]) for i in range(len(sequence) - k + 1)]\n",
    "    G = nx.DiGraph(edges)\n",
    "    pos = nx.spring_layout(G, seed=42)  # Fixed layout for consistent graph\n",
    "    nx.draw(G, pos, with_labels=True, node_size=10, font_size=1, arrowsize=5)\n",
    "    plt.title('De Bruijn Graph')\n",
    "    plt.savefig(output_filename, format='svg')\n",
    "    plt.clf()\n",
    "\n",
    "# HTML formatting functions\n",
    "def P(text):\n",
    "    return f\"<p>{text}</p>\"\n",
    "\n",
    "def H3(text):\n",
    "    return f\"<h3>{text}</h3>\"\n",
    "\n",
    "# Function to generate reports\n",
    "def generate_report(data):\n",
    "    global minSize\n",
    "    genome = data['Assembled Genome']\n",
    "    genome_with_junction = data['Assembled Genome with Junctions']\n",
    "    PCRs = data['PCR_validation_settings']\n",
    "    \n",
    "    report_id = f\"Prediction_{data.name}\"\n",
    "    path = os.path.join(\"Results\", report_id)\n",
    "    os.makedirs(os.path.join(path, \"assets\"), exist_ok=True)\n",
    "\n",
    "    # Save FASTA files\n",
    "    fasta_content = f\">{report_id}\\n\" + \"\\n\".join(genome[i:i + 70] for i in range(0, len(genome), 70))\n",
    "    fasta_with_junctions_content = f\">{report_id}_with_junctions\\n\" + \"\\n\".join(\n",
    "        genome_with_junction[i:i + 70] for i in range(0, len(genome_with_junction), 70)\n",
    "    )\n",
    "    with open(os.path.join(path, f\"{report_id}.fasta\"), \"w\") as fasta_file:\n",
    "        fasta_file.write(fasta_content)\n",
    "    with open(os.path.join(path, f\"{report_id}_with_junctions.fasta\"), \"w\") as fasta_junction_file:\n",
    "        fasta_junction_file.write(fasta_with_junctions_content)\n",
    "\n",
    "    # Generate De Bruijn graph\n",
    "    #de_bruijn_path = os.path.join(path, \"assets\", f\"{report_id}_de_bruijn.svg\")\n",
    "    #de_bruijn(genome, minSize, de_bruijn_path)\n",
    "\n",
    "    # Generate nucleotide percentage chart\n",
    "    nuc_percentage_path = os.path.join(path, \"assets\", f\"{report_id}_nucleotide_percentages.svg\")\n",
    "    nuc_percentage(genome, As, Ts, Cs, Gs, nuc_percentage_path)\n",
    "\n",
    "    # Generate HTML report\n",
    "    html = f\"<html><head><title>{report_id}</title></head><body>\"\n",
    "    html += H3(\"Sequences\")\n",
    "    html += P(fasta_content.replace(\"\\n\", \"<br>\"))\n",
    "    html += P(fasta_with_junctions_content.replace(\"\\n\", \"<br>\"))\n",
    "    if data['BLASTn'] != None:\n",
    "        html += data['BLASTn']\n",
    "    html += H3(\"Recommended PCRs for Validation\")\n",
    "    for PCR in PCRs:\n",
    "        html += P(f\"Forward Primer: {PCR[0]}, Tm: {PCR[2]}째C\")\n",
    "        html += P(f\"Reverse Primer: {PCR[1]}, Tm: {PCR[3]}째C\")\n",
    "        html += P(f\"Product Size: {PCR[4]} bp\")\n",
    "        html += P(f\"Product Sequence: <br>{'<br>'.join(PCR[5][i:i + 70] for i in range(0, len(PCR[5]), 70))}\")\n",
    "    html += f'<img src=\"{os.path.join(\"assets\", f\"{report_id}_nucleotide_percentages.svg\")}\" alt=\"Nucleotide Percentages\" style=\"width:50%;\">'\n",
    "    html += \"</body></html>\"\n",
    "\n",
    "    with open(os.path.join(path, f\"{report_id}_summary.html\"), \"w\") as html_file:\n",
    "        html_file.write(html)\n",
    "\n",
    "# Main execution\n",
    "os.makedirs(\"Results\", exist_ok=True)\n",
    "df.apply(generate_report, axis=1)\n",
    "print('De-novo assembly report generated.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
